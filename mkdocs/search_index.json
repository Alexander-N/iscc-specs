{
    "docs": [
        {
            "location": "/",
            "text": "ISCC - International Standard Content Code\n\u00b6\n\n\n\n\nAttention\n\n\nThis site is work in progress!\n\n\n\n\nThe latest version of these pages can be found at \niscc.codes\n\n\nBetter Content Identifiers\n\u00b6\n\n\nCurrently, the media industry is still relying on identifiers that were designed for physical products such as printed books and magazines. However, traditional identifiers (like ISBN, ISSN or ISRC) fall short of the requirements for digital trade.\n\n\nFreely accessible standard \nidentifiers\n, which are specifically \ndesigned for digital content\n, are a fundamental prerequisite for transactions and sales activities in a digital and increasingly heterogeneous media environment.\n\n\nWith better identifiers for digital content, the entire ecosystem becomes more efficient.\n\n\n\n\nHow it works\n\u00b6\n\n\nThe major innovation of the ISCC: identifiers are generated algorithmically and in a decentralized way from a basic set of metadata and the content itself. This inseparably links any specific content to a specific ID.\n\n\nThe ISCC is a unique, hierarchically structured composite identifier. It is built from a generic and balanced mix of content-derived, locality-sensitive and similarity-preserving hashes generated from metadata and content.",
            "title": "Introduction"
        },
        {
            "location": "/#iscc-international-standard-content-code",
            "text": "Attention  This site is work in progress!   The latest version of these pages can be found at  iscc.codes",
            "title": "ISCC - International Standard Content Code"
        },
        {
            "location": "/#better-content-identifiers",
            "text": "Currently, the media industry is still relying on identifiers that were designed for physical products such as printed books and magazines. However, traditional identifiers (like ISBN, ISSN or ISRC) fall short of the requirements for digital trade.  Freely accessible standard  identifiers , which are specifically  designed for digital content , are a fundamental prerequisite for transactions and sales activities in a digital and increasingly heterogeneous media environment.  With better identifiers for digital content, the entire ecosystem becomes more efficient.",
            "title": "Better Content Identifiers"
        },
        {
            "location": "/#how-it-works",
            "text": "The major innovation of the ISCC: identifiers are generated algorithmically and in a decentralized way from a basic set of metadata and the content itself. This inseparably links any specific content to a specific ID.  The ISCC is a unique, hierarchically structured composite identifier. It is built from a generic and balanced mix of content-derived, locality-sensitive and similarity-preserving hashes generated from metadata and content.",
            "title": "How it works"
        },
        {
            "location": "/concept/",
            "text": "ISCC - Concept\n\u00b6\n\n\nThe internet is shifting towards a network of decentralized peer-to-peer transactions. If we want our transactions on the emerging blockchain networks to be about content we need standardized ways to address content. Our transactions might be payments, attributions, reputation, certification, licenses or entirely new kinds of value transfer. All this will happen much faster and easier if we, as a community, can agree on how to identify content in a decentralized environment. This is the first draft of an open proposal to the wider content community for a common content identifier. We would like to share our ideas and spark a conversation with journalists, news agencies, content creators, publishers, distributors, libraries, musicians, scientists, developers, lawyers, rights organizations and all the other participants of the content ecosystem.\n\n\nIntroduction\n\u00b6\n\n\nThere are many\n existing standards\n for media identifiers serving a wide array of use cases. For example book publishing uses the \nISBN\n, magazines have the \nISSN\n, music industry has \nISRC\n, film has \nISAN\n and science has \nDOI\n - each of them serving a set of specific purposes. These identifiers have important roles across many layers. The \nstructure and management\n of these \nglobal identifiers\n strongly correlates with the grade of achievable \nautomation\n and potential for \ninnovation\n within and across different sectors of the media industries. Some communities, like online journalism, don't even have any global persistent identifiers for their content.\n\n\nMany of the established standards manage registration of identifiers in \ncentralized \nor\nhierarchical systems\n involving manual and costly processes. Often the associated metadata is not easily or freely accessible for third parties (if available at all). The overhead, cost and general properties of these systems make them unsuitable for many innovative use cases. Existing and established standards have trouble keeping up with the fast evolving digital economy. For example nowadays major e-book retailers do not even require an \nISBN\n and instead establish their own proprietary identifiers. Amazon has the \nASIN\n, Apple has \nApple-ID\n and Google has \nGKEY\n. The fast paced development of the digital media economy has led to an increasing fragmentation of identifiers and new barriers in interoperability. For many tasks current systems need to track and match all the different vendor specific IDs, which is an inefficient and error prone process.\n\n\nAdvances in data structures, algorithms, machine learning and the uprise of crypto economics allows us to invent \nnew\n kinds of \nmedia identifiers\n and \nre-imagine existing identifiers\n with innovative use cases in mind. Blockchains and Smart Contracts offer great opportunities in solving many of the challenges of identifier registration, like centralized management, data duplication and disambiguation, vendor lock-in and long term data retention.\n\n\nThis is an open proposal to the digital media community and explores the possibilities of a\ndecentralized \ncontent identifier system. We\u2019d like to establish an open standard for persistent, unique, vendor independent and content derived cross-media identifiers that are stored and managed in a global and decentralized blockchain. We envision a self-governing ecosystem with a low barrier of entry where \ncommercial and non-commercial\n initiatives can both innovate and thrive next to each other.\n\n\nMedia Identifiers for Blockchains\n\u00b6\n\n\nMedia cataloging systems tend to get out of hand and become complex and often unmanageable. Our design proposal is focused on keeping the ISCC system as simple and more importantly as \nautomatable\n as possible, while maximizing practical value for the most important use cases \u2014 meaning you should get out more than you have to put in. With this in mind we come to the following basic design decisions:\n\n\nA \u201cMeaningful\u201d Identifier\n\u00b6\n\n\nIn traditional database systems it is recommended practice to work with \nsurrogate keys\n as identifiers. A surrogate key has no business meaning and is completely decoupled from the data it identifies. Uniqueness of such identifiers is guaranteed either via centralized incremental assignment by the database system or via random UUIDs which have a very low probability of collisions. While random UUIDs could be generated in a decentralized way, both approaches require some external authority that establishes or certifies the linkage between the identifier and the associated metadata and content. This is why we decided to go with a \u201cmeaningful\u201d\ncontent and metadata derived identifier (CMDI)\n. Anyone will be able to verify that a specific identifier indeed belongs to a given digital content. Even better, anyone can \u201cfind\u201d the identifier for a given content without the need to consult external data sources. This approach also captures essential information about the media in the identifier itself, which is very useful in scenarios of machine learning and data analytics.\n\n\nA Decentralized Identifier\n\u00b6\n\n\nWe would like our identifier to be registry agnostic. This means that identifiers can be self-issued in a decentralized and parallel fashion without the need to ask for permission. Even if identifiers are not registered in a central database or on a public blockchain they are still useful in cases where multiple independent parties exchange information about content. The CMDI approach is helpful with common issues like data integrity, validation, de-duplication and disambiguation.\n\n\nStorage Considerations\n\u00b6\n\n\nOn a typical public blockchain all data is \nfully replicated\n among participants. This allows for independent and autonomous validation of transactions. All blockchain data is highly available, tamper-proof and accessible for free. However, under high load the limited transaction capacity (storage space per unit of time) creates a transaction fee market. This leads to\n growing transaction costs\n and makes storage space a scarce and increasingly precious resource. So it is mandatory for our identifier and its eventual metadata schema to be very \nspace efficient \nto maximize benefit at minimum cost. The basic metadata that will be required to generate and register identifiers must be:\n\n\n\n\nminimal in scope\n\n\nclearly specified\n\n\nrobust against human error\n\n\nenforced on technical level\n\n\nadequate for public use (no legal or privacy issues)\n\n\n\n\nLayers of Digital Media Identification\n\u00b6\n\n\nWhile we examined existing identifiers we discovered that there is often much confusion about the extent or coverage of what exactly is being identified by a given system. With our idea for a generic cross-media identifier we want to put special weight on being precise with our definitions and found it helpful to distinguish between \u201cdifferent layers of digital media identification\". We found that these layers exist naturally on a scale from abstract to concrete. Our analysis also showed that existing standard identifiers only operate on one or at most two of such layers. The ISCC will be designed as a \ncomposite identifier\n that takes the different layers of media identification into consideration:\n\n\nLayer 1 \u2013 Abstract Creation\n\u00b6\n\n\nIn the first and most abstract layer we are concerned with distinguishing between different works or creations in the \nbroadest possible sense\n. The scope of identification is completely independent of any manifestations of the work, be it physical or digital in nature. It is also agnostic to creators, rights holders or any specific interpretations, expressions or language versions of a work. It only relates to the intangible creation - the idea itself.\n\n\nLayer 2 \u2013 Semantic Field\n\u00b6\n\n\nThis layer relates to the meaning or essence of a work. It is an amorphous collection or combination of facts, concepts, categories, subjects, topics, themes, assumptions, observations, conclusions, beliefs and other intangible things that the content conveys. The scope of identification is a set of coordinates within a finite and multidimensional semantic space.\n\n\nLayer 3 \u2013 Generic Manifestation\n\u00b6\n\n\nIn this layer we are concerned with the literal structure of a media type specific and normalized manifestation. Namely the basic text, image, audio or video content independent of its semantic meaning or media file encoding and with a tolerance to variation. This \"tolerance to variation\" bundles a set of different versions with corrections, revisions, edits, updates, personalizations, different format encodings or data compressions of the same content under one grouping identifier. A generic manifestation is independent of a final digital media product and is specific to an expression, version or interpretation of a work.\n\n\nUnfortunately it is not obvious where generic manifestation of a work ends and another one starts. It depends on human interpretation and context. How much editing do we allow before we call it a \u201cdifferent\u201d manifestation and give it a different identifier. A practical but only partial solution to this problem is to create a algorithmically defined and testable spectrum of tolerance to variation per media type. This can provide a stable and repeatable process to distinguish between generic content manifestations. But it is important to understand that such a process is not expected to yield results that are always intuitive to human expectations as to where exactly boundaries should be.\n\n\nLayer 4 \u2013 Media Specific Manifestation\n\u00b6\n\n\nThis layer relates to a \nmanifestation with a specific encoding\n. It identifies a \ndata-file\n encoded and offered in a specific \nmedia format \nincluding a tolerance to variation to account for minor edits and updates within a format without creating a new identifier. For example one could distinguish between the PDF, DOCX or WEBSITE versions of the same content as generated from a single source publishing system. This layer does only distinguish between products or \"artifacts\" with a given packaging or encoding.\n\n\nLayer 5 \u2013 Exact Representation\n\u00b6\n\n\nIn this layer we identify a data-file by its exact binary representation without any interpretation of meaning and without any ambiguity. Even a minimal change in data that might not change the interpretation of content would create a different identifier. Like the first four layers, this layer does also \nnot \nexpress any information related to \ncontent location\n or \nownership\n.\n\n\nLayer 6 \u2013 Individual Copy\n\u00b6\n\n\nIn the physical world we would call a specific book (one that you can take out of your shelve) an \nindividual copy\n. This implies a notion of \nlocality \nand \nownership\n. In the digital world the semantics of an individual copy are very different. An individual copy might be distinguished by a license you own or by a personalized watermark applied by the retailer at time of sale or some digital annotations you have added to your digital media file. While there can only ever be \none exact\n individual copy of a \nphysical object\n, there always can be \nendless replicas\n of an \"individual copy\" of a \ndigital object\n. It is very important to keep this difference in mind. Ignoring this fact has caused countless misunderstandings and is the source of confusion throughout the media industry \u2013 especially in realm of copyright and license discussions.\n\n\nWe could try to define an \nindividual digital copy\n by its location and exact content on a specific physical storage medium (like a DVD, SSD ...). But this does not account for the fact that it is nearly impossible to stop someone from creating an exact replica of that data or at least a snapshot or recording of the presentation of that data on another storage location.\n\n\nAnd most importantly such a replica does not affect the original data and even less can make it magically disappear. In contrast, if you give your individual copy of your book to someone else, you won't \n\"have it\"\n anymore. It is clear, that with digital media this \ncannot reliably be the case\n. The only way would be to build a \ntamper-proof physical device\n (secure element) that does not reveal the data itself, which would defeat the purpose by making the content itself unavailable. But there are ways to partially simulate such inherently physical properties in the digital world. Most notably with the emergence of blockchain technology it is now possible to have a \ncryptographically secured\n and publicly notarized tamper-proof \ncertificate of ownership. \n This can serve as a record of agreement about ownership of an \u201cindividual copy\u201d. But is does not by itself enforce location or accessibility of the content, nor does it prove the authorization of the certifying party itself or the legal validity of the agreement.\n\n\nAlgorithmic Tools\n\u00b6\n\n\nWhile many details about the ISCC are still up for discussion we are quite confident about some of the general algorithmic families that will make it into the final specification for the identifier. These will play an important role in how we generate the different components of the identifier:\n\n\n\n\nSimilarity preserving hash functions (Simhash, Minhash ...)\n\n\nPerceptual hashing (pHash, Blockhash, Chromaprint \u2026)\n\n\nContent defined chunking (Rabin-Karp, FastCDC ...)\n\n\nMerkle trees\n\n\n\n\nISCC Proof-of-Concept\n\u00b6\n\n\nBefore we settle on the details of the proposed ISCC identifier, we want to build a simple and reduced proof-of-concept implementation of our ideas. It will enable us and other developers to test with real world data and systems and find out early what works and what doesn't.\n\n\n\n\nThe minimal viable, first iteration ISCC will be a byte structure built from the following components:\n\n\nMetaID\n\u00b6\n\n\nThe MetaID will be generated as a similarity preserving hash from minimal generic metadata like \ntitle \nand \ncreators\n. It operates on \nLayer 1 \n and identifies an intangible creation. It is the first and most generic grouping element of the identifier. We will be experimenting with different n-gram sizes and bit-length to find the practical limits of precision and recall for generic metadata. We will also specify a process to disambiguate unintended collisions by adding optional metadata.\n\n\nPartial Content Flag\n\u00b6\n\n\nThe Partial Content Flag is a 1-bit flag that indicates if the remaining elements relate to the complete work or only to a subset of it.\n\n\nMedia Type Flag\n\u00b6\n\n\nThe Media Type Flag is a 3 bit flag that allows us to distinguish between up to 8 generic media types\n (GMTs)\n to which our ContentID component applies. We define a generic media type as\nbasic content type\n such as plain text or raw pixel data that will be specified exactly and extracted from more complex file formats or encodings. We will start with generic text and image types and add audio, video and mixed types later.\n\n\nContentID\n\u00b6\n\n\nThe ContentID operates on \nLayer 3\n and will be a GMT-specific similarity preserving hash generated from extracted content. It identifies the normalized content of a specific GMT, independent of file format or encoding. It relates to the structural essence of the content and groups similar GMT-specific manifestations of the abstract creation or parts of it (as indicated by the Partial Content Flag). For practical reasons we intentionally skip a \nLayer 2\n component at this time. It would add unnecessary complexity for a basic proof-of-concept implementation.\n\n\nDataID\n\u00b6\n\n\nThe DataID operates on \nLayer 4 \nand will be a similarity preserving hash generated from shift-resistant content-defined chunks from the raw data of the encoded media blob. It groups complete encoded files with similar content and encoding. This component does not distinguish between GMTs as the files may include multiple different generic media types.\n\n\nInstanceID\n\u00b6\n\n\nThe InstanceID operates on \nLayer 5 \nand will be the top hash of a merkle tree generated from (potentially content-defined) chunks of raw data of an encoded media blob. It identifies a concrete manifestation and proves the integrity of the full content. We use the merkle tree structure because it also allows as to verify integrity of partial chunks without having to have the full data available. This will be very useful in any scenarios of distributed data storage.\n\n\nWe intentionally skip \nLayer 6\n at this stage as content ownership and location will be handled on the blockchain layer of the stack and not by the ISCC identifier itself.\n\n\nA first experimental prototype of the ISCC idea is in development on \nGithub\n.",
            "title": "Concept"
        },
        {
            "location": "/concept/#iscc-concept",
            "text": "The internet is shifting towards a network of decentralized peer-to-peer transactions. If we want our transactions on the emerging blockchain networks to be about content we need standardized ways to address content. Our transactions might be payments, attributions, reputation, certification, licenses or entirely new kinds of value transfer. All this will happen much faster and easier if we, as a community, can agree on how to identify content in a decentralized environment. This is the first draft of an open proposal to the wider content community for a common content identifier. We would like to share our ideas and spark a conversation with journalists, news agencies, content creators, publishers, distributors, libraries, musicians, scientists, developers, lawyers, rights organizations and all the other participants of the content ecosystem.",
            "title": "ISCC - Concept"
        },
        {
            "location": "/concept/#introduction",
            "text": "There are many  existing standards  for media identifiers serving a wide array of use cases. For example book publishing uses the  ISBN , magazines have the  ISSN , music industry has  ISRC , film has  ISAN  and science has  DOI  - each of them serving a set of specific purposes. These identifiers have important roles across many layers. The  structure and management  of these  global identifiers  strongly correlates with the grade of achievable  automation  and potential for  innovation  within and across different sectors of the media industries. Some communities, like online journalism, don't even have any global persistent identifiers for their content.  Many of the established standards manage registration of identifiers in  centralized  or hierarchical systems  involving manual and costly processes. Often the associated metadata is not easily or freely accessible for third parties (if available at all). The overhead, cost and general properties of these systems make them unsuitable for many innovative use cases. Existing and established standards have trouble keeping up with the fast evolving digital economy. For example nowadays major e-book retailers do not even require an  ISBN  and instead establish their own proprietary identifiers. Amazon has the  ASIN , Apple has  Apple-ID  and Google has  GKEY . The fast paced development of the digital media economy has led to an increasing fragmentation of identifiers and new barriers in interoperability. For many tasks current systems need to track and match all the different vendor specific IDs, which is an inefficient and error prone process.  Advances in data structures, algorithms, machine learning and the uprise of crypto economics allows us to invent  new  kinds of  media identifiers  and  re-imagine existing identifiers  with innovative use cases in mind. Blockchains and Smart Contracts offer great opportunities in solving many of the challenges of identifier registration, like centralized management, data duplication and disambiguation, vendor lock-in and long term data retention.  This is an open proposal to the digital media community and explores the possibilities of a decentralized  content identifier system. We\u2019d like to establish an open standard for persistent, unique, vendor independent and content derived cross-media identifiers that are stored and managed in a global and decentralized blockchain. We envision a self-governing ecosystem with a low barrier of entry where  commercial and non-commercial  initiatives can both innovate and thrive next to each other.",
            "title": "Introduction"
        },
        {
            "location": "/concept/#media-identifiers-for-blockchains",
            "text": "Media cataloging systems tend to get out of hand and become complex and often unmanageable. Our design proposal is focused on keeping the ISCC system as simple and more importantly as  automatable  as possible, while maximizing practical value for the most important use cases \u2014 meaning you should get out more than you have to put in. With this in mind we come to the following basic design decisions:",
            "title": "Media Identifiers for Blockchains"
        },
        {
            "location": "/concept/#a-meaningful-identifier",
            "text": "In traditional database systems it is recommended practice to work with  surrogate keys  as identifiers. A surrogate key has no business meaning and is completely decoupled from the data it identifies. Uniqueness of such identifiers is guaranteed either via centralized incremental assignment by the database system or via random UUIDs which have a very low probability of collisions. While random UUIDs could be generated in a decentralized way, both approaches require some external authority that establishes or certifies the linkage between the identifier and the associated metadata and content. This is why we decided to go with a \u201cmeaningful\u201d content and metadata derived identifier (CMDI) . Anyone will be able to verify that a specific identifier indeed belongs to a given digital content. Even better, anyone can \u201cfind\u201d the identifier for a given content without the need to consult external data sources. This approach also captures essential information about the media in the identifier itself, which is very useful in scenarios of machine learning and data analytics.",
            "title": "A \u201cMeaningful\u201d Identifier"
        },
        {
            "location": "/concept/#a-decentralized-identifier",
            "text": "We would like our identifier to be registry agnostic. This means that identifiers can be self-issued in a decentralized and parallel fashion without the need to ask for permission. Even if identifiers are not registered in a central database or on a public blockchain they are still useful in cases where multiple independent parties exchange information about content. The CMDI approach is helpful with common issues like data integrity, validation, de-duplication and disambiguation.",
            "title": "A Decentralized Identifier"
        },
        {
            "location": "/concept/#storage-considerations",
            "text": "On a typical public blockchain all data is  fully replicated  among participants. This allows for independent and autonomous validation of transactions. All blockchain data is highly available, tamper-proof and accessible for free. However, under high load the limited transaction capacity (storage space per unit of time) creates a transaction fee market. This leads to  growing transaction costs  and makes storage space a scarce and increasingly precious resource. So it is mandatory for our identifier and its eventual metadata schema to be very  space efficient  to maximize benefit at minimum cost. The basic metadata that will be required to generate and register identifiers must be:   minimal in scope  clearly specified  robust against human error  enforced on technical level  adequate for public use (no legal or privacy issues)",
            "title": "Storage Considerations"
        },
        {
            "location": "/concept/#layers-of-digital-media-identification",
            "text": "While we examined existing identifiers we discovered that there is often much confusion about the extent or coverage of what exactly is being identified by a given system. With our idea for a generic cross-media identifier we want to put special weight on being precise with our definitions and found it helpful to distinguish between \u201cdifferent layers of digital media identification\". We found that these layers exist naturally on a scale from abstract to concrete. Our analysis also showed that existing standard identifiers only operate on one or at most two of such layers. The ISCC will be designed as a  composite identifier  that takes the different layers of media identification into consideration:",
            "title": "Layers of Digital Media Identification"
        },
        {
            "location": "/concept/#layer-1-abstract-creation",
            "text": "In the first and most abstract layer we are concerned with distinguishing between different works or creations in the  broadest possible sense . The scope of identification is completely independent of any manifestations of the work, be it physical or digital in nature. It is also agnostic to creators, rights holders or any specific interpretations, expressions or language versions of a work. It only relates to the intangible creation - the idea itself.",
            "title": "Layer 1 \u2013 Abstract Creation"
        },
        {
            "location": "/concept/#layer-2-semantic-field",
            "text": "This layer relates to the meaning or essence of a work. It is an amorphous collection or combination of facts, concepts, categories, subjects, topics, themes, assumptions, observations, conclusions, beliefs and other intangible things that the content conveys. The scope of identification is a set of coordinates within a finite and multidimensional semantic space.",
            "title": "Layer 2 \u2013 Semantic Field"
        },
        {
            "location": "/concept/#layer-3-generic-manifestation",
            "text": "In this layer we are concerned with the literal structure of a media type specific and normalized manifestation. Namely the basic text, image, audio or video content independent of its semantic meaning or media file encoding and with a tolerance to variation. This \"tolerance to variation\" bundles a set of different versions with corrections, revisions, edits, updates, personalizations, different format encodings or data compressions of the same content under one grouping identifier. A generic manifestation is independent of a final digital media product and is specific to an expression, version or interpretation of a work.  Unfortunately it is not obvious where generic manifestation of a work ends and another one starts. It depends on human interpretation and context. How much editing do we allow before we call it a \u201cdifferent\u201d manifestation and give it a different identifier. A practical but only partial solution to this problem is to create a algorithmically defined and testable spectrum of tolerance to variation per media type. This can provide a stable and repeatable process to distinguish between generic content manifestations. But it is important to understand that such a process is not expected to yield results that are always intuitive to human expectations as to where exactly boundaries should be.",
            "title": "Layer 3 \u2013 Generic Manifestation"
        },
        {
            "location": "/concept/#layer-4-media-specific-manifestation",
            "text": "This layer relates to a  manifestation with a specific encoding . It identifies a  data-file  encoded and offered in a specific  media format  including a tolerance to variation to account for minor edits and updates within a format without creating a new identifier. For example one could distinguish between the PDF, DOCX or WEBSITE versions of the same content as generated from a single source publishing system. This layer does only distinguish between products or \"artifacts\" with a given packaging or encoding.",
            "title": "Layer 4 \u2013 Media Specific Manifestation"
        },
        {
            "location": "/concept/#layer-5-exact-representation",
            "text": "In this layer we identify a data-file by its exact binary representation without any interpretation of meaning and without any ambiguity. Even a minimal change in data that might not change the interpretation of content would create a different identifier. Like the first four layers, this layer does also  not  express any information related to  content location  or  ownership .",
            "title": "Layer 5 \u2013 Exact Representation"
        },
        {
            "location": "/concept/#layer-6-individual-copy",
            "text": "In the physical world we would call a specific book (one that you can take out of your shelve) an  individual copy . This implies a notion of  locality  and  ownership . In the digital world the semantics of an individual copy are very different. An individual copy might be distinguished by a license you own or by a personalized watermark applied by the retailer at time of sale or some digital annotations you have added to your digital media file. While there can only ever be  one exact  individual copy of a  physical object , there always can be  endless replicas  of an \"individual copy\" of a  digital object . It is very important to keep this difference in mind. Ignoring this fact has caused countless misunderstandings and is the source of confusion throughout the media industry \u2013 especially in realm of copyright and license discussions.  We could try to define an  individual digital copy  by its location and exact content on a specific physical storage medium (like a DVD, SSD ...). But this does not account for the fact that it is nearly impossible to stop someone from creating an exact replica of that data or at least a snapshot or recording of the presentation of that data on another storage location.  And most importantly such a replica does not affect the original data and even less can make it magically disappear. In contrast, if you give your individual copy of your book to someone else, you won't  \"have it\"  anymore. It is clear, that with digital media this  cannot reliably be the case . The only way would be to build a  tamper-proof physical device  (secure element) that does not reveal the data itself, which would defeat the purpose by making the content itself unavailable. But there are ways to partially simulate such inherently physical properties in the digital world. Most notably with the emergence of blockchain technology it is now possible to have a  cryptographically secured  and publicly notarized tamper-proof  certificate of ownership.   This can serve as a record of agreement about ownership of an \u201cindividual copy\u201d. But is does not by itself enforce location or accessibility of the content, nor does it prove the authorization of the certifying party itself or the legal validity of the agreement.",
            "title": "Layer 6 \u2013 Individual Copy"
        },
        {
            "location": "/concept/#algorithmic-tools",
            "text": "While many details about the ISCC are still up for discussion we are quite confident about some of the general algorithmic families that will make it into the final specification for the identifier. These will play an important role in how we generate the different components of the identifier:   Similarity preserving hash functions (Simhash, Minhash ...)  Perceptual hashing (pHash, Blockhash, Chromaprint \u2026)  Content defined chunking (Rabin-Karp, FastCDC ...)  Merkle trees",
            "title": "Algorithmic Tools"
        },
        {
            "location": "/concept/#iscc-proof-of-concept",
            "text": "Before we settle on the details of the proposed ISCC identifier, we want to build a simple and reduced proof-of-concept implementation of our ideas. It will enable us and other developers to test with real world data and systems and find out early what works and what doesn't.   The minimal viable, first iteration ISCC will be a byte structure built from the following components:",
            "title": "ISCC Proof-of-Concept"
        },
        {
            "location": "/concept/#metaid",
            "text": "The MetaID will be generated as a similarity preserving hash from minimal generic metadata like  title  and  creators . It operates on  Layer 1   and identifies an intangible creation. It is the first and most generic grouping element of the identifier. We will be experimenting with different n-gram sizes and bit-length to find the practical limits of precision and recall for generic metadata. We will also specify a process to disambiguate unintended collisions by adding optional metadata.",
            "title": "MetaID"
        },
        {
            "location": "/concept/#partial-content-flag",
            "text": "The Partial Content Flag is a 1-bit flag that indicates if the remaining elements relate to the complete work or only to a subset of it.",
            "title": "Partial Content Flag"
        },
        {
            "location": "/concept/#media-type-flag",
            "text": "The Media Type Flag is a 3 bit flag that allows us to distinguish between up to 8 generic media types  (GMTs)  to which our ContentID component applies. We define a generic media type as basic content type  such as plain text or raw pixel data that will be specified exactly and extracted from more complex file formats or encodings. We will start with generic text and image types and add audio, video and mixed types later.",
            "title": "Media Type Flag"
        },
        {
            "location": "/concept/#contentid",
            "text": "The ContentID operates on  Layer 3  and will be a GMT-specific similarity preserving hash generated from extracted content. It identifies the normalized content of a specific GMT, independent of file format or encoding. It relates to the structural essence of the content and groups similar GMT-specific manifestations of the abstract creation or parts of it (as indicated by the Partial Content Flag). For practical reasons we intentionally skip a  Layer 2  component at this time. It would add unnecessary complexity for a basic proof-of-concept implementation.",
            "title": "ContentID"
        },
        {
            "location": "/concept/#dataid",
            "text": "The DataID operates on  Layer 4  and will be a similarity preserving hash generated from shift-resistant content-defined chunks from the raw data of the encoded media blob. It groups complete encoded files with similar content and encoding. This component does not distinguish between GMTs as the files may include multiple different generic media types.",
            "title": "DataID"
        },
        {
            "location": "/concept/#instanceid",
            "text": "The InstanceID operates on  Layer 5  and will be the top hash of a merkle tree generated from (potentially content-defined) chunks of raw data of an encoded media blob. It identifies a concrete manifestation and proves the integrity of the full content. We use the merkle tree structure because it also allows as to verify integrity of partial chunks without having to have the full data available. This will be very useful in any scenarios of distributed data storage.  We intentionally skip  Layer 6  at this stage as content ownership and location will be handled on the blockchain layer of the stack and not by the ISCC identifier itself.  A first experimental prototype of the ISCC idea is in development on  Github .",
            "title": "InstanceID"
        },
        {
            "location": "/specification/",
            "text": "ISCC - Specification Draft\n\u00b6\n\n\n\n\nWarning\n\n\nThis document is a work in progress draft! It may be updated, replaced, or obsoleted by other documents at any time. This document must not be used as reference material or cited other than as \"work in progress\".\n\n\n\n\nAbstract\n\u00b6\n\n\nThe \nInternational Standard Content Code\n (ISCC), is an open and decentralized digital media identifier. An ISCC can be created from digital content and its basic metadata by anybody who follows the procedures of the ISCC specification or by using open source software that supports ISCC creation conforming to the ISCC specification.\n\n\nNote to Readers\n\u00b6\n\n\nFor public discussion of issues for this draft please use the Github issue tracker: \nhttps://github.com/coblo/iscc-specs/issues\n.\n\n\nThe latest published version of this draft can be found at \nhttp://iscc.codes/specification/\n. \n\n\nPublic discussion and contributions are welcome.\n\n\nAbout this Document\n\u00b6\n\n\nThis document proposes an open and vendor neutral ISCC standard and describes the technical procedures to create and manage ISCC identifiers. It is produced by the \nContent Blockchain Project\n and it aimed to become the definitive guide to the ISCC standard for technical implementors. The content is determined by its authors in an open consensus process.\n\n\nConventions and Terminology\n\u00b6\n\n\nThe key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\", \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"MAY\", and \"OPTIONAL\" in this document are to be interpreted as described in \nRFC 2119\n [RFC2119].\n\n\nDefinitions\n\u00b6\n\n\n\n\nGMT\n\n\nGeneric Media Type: A basic digital content type such as UTF-8 encoded plain text or raw pixel data.\n\n\nISCC\n\n\nInternational Standard Content Code\n\n\nISCC Code\n\n\nThe base32 encoded representation of an ISCC\n\n\nISCC Digest\n\n\nThe raw binary data of an ISCC\n\n\nISCC ID\n\n\nThe integer representation of an ISCC\n\n\n\n\nIntroduction\n\u00b6\n\n\nThe ISCC aims to permanently identify the content of a given digital media object at multiple levels of \ngranularity\n. It is algorithmically generated from basic metadata and the contents of the digital media object which it identifies. It is designed for being registered and stored on a public decentralized blockchain. An ISCC for a media object can be created by anybody, not just by the author or publisher of a content or by a centralized registrar. By itself the ISCC does not make any statement or claim about authorship or ownership of the identified content.\n\n\nISCC Structure\n\u00b6\n\n\nThe \nISCC Digest\n is a fixed size sequence of 32 bytes (256 bits) assembled from multiple sub-components. The printable \nISCC Code\n is an \nRFC 4648\n base32\n1\n encoded string representation of an \nISCC Digest\n. This is a high-level overview of the ISCC creation process:\n\n\n\n\nComponents\n\u00b6\n\n\nThe \nISCC Digest\n is built from multiple self-describing 64-bit components:\n\n\n\n\n\n\n\n\nComponents:\n\n\nMeta-ID\n\n\nContent-ID\n\n\nData-ID\n\n\nInstance-ID\n\n\n\n\n\n\n\n\n\n\nContext:\n\n\nIntangible creation\n\n\nContent similarity\n\n\nData similarity\n\n\nData checksum\n\n\n\n\n\n\nInput:\n\n\nMetadata\n\n\nExtracted  content\n\n\nRaw data\n\n\nRaw data\n\n\n\n\n\n\nAlgorithms:\n\n\nSimilarity Hash\n\n\nType specific\n\n\nCDC\n, Similarity Hash\n\n\nCDC\n, Hash Tree\n\n\n\n\n\n\nSize:\n\n\n64 bits\n\n\n64 bits\n\n\n64 bits\n\n\n64 bits\n\n\n\n\n\n\n\n\nEach component is guaranteed to fit into a 64-bit unsigned integer value. The components may be used independently by applications for various purposes but must be combined into a 52 \ncharacter\n string (55 with hyphens) for a fully qualified ISCC code. The components must be combined in the fixed order of Meta-ID, Content-ID, Data-ID, Instance-ID and may be separated by hyphens.\n\n\n\n\nTodo\n\n\nDescribe coded format with prefix, colon, components +- hyphens\n\n\n\n\nComponent types\n\u00b6\n\n\nEach component has the same basic structure of a 1-byte header and a 7-byte main section\n2\n. Each component can thus be fit into a 64-bit integer value. The header-byte of each component is subdivided into 2 nibbles (4 bits). The first nibble specifies the component type while the second nibble is component specific.\n\n\n\n\n\n\n\n\nComponent\n\n\nNibble-1\n\n\nNibble-2\n\n\nByte\n\n\n\n\n\n\n\n\n\n\nMeta-ID\n\n\n0000\n\n\n0000 - ISCC version (0)\n\n\n0x00\n\n\n\n\n\n\nContent-ID\n\n\n0001\n\n\n0000 - ContentType Text (0)\n\n\n0x10\n\n\n\n\n\n\nData-ID\n\n\n0010\n\n\n0000 - Reserved\n\n\n0x20\n\n\n\n\n\n\nInstance-ID\n\n\n0011\n\n\n0000 - Reserved\n\n\n0x30\n\n\n\n\n\n\n\n\nMeta-ID\n\u00b6\n\n\nThe Meta-ID is built from minimal and generic metadata of the content to be identified. All \ntext\n information supplied to the META-ID generating function is assumed to be UTF-8 encoded. Errors during decoding the bytestring input to a native Unicode must terminate the process and should not be silenced. An ISCC generating application must provide a \ngenerate_meta_id\n function that accepts the following input fields:\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nRequired\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntitle\n\n\ntext\n\n\nYes\n\n\nThe title of an intangible creation.\n\n\n\n\n\n\ncreators\n3\n\n\ntext\n\n\nNo\n\n\nOne or more semicolon separated names of the original creators of the content.\n\n\n\n\n\n\nextra\n\n\ntext\n\n\nNo\n\n\nA short statement that distinguishes this intangible creation from another one.\n\n\n\n\n\n\nversion\n\n\ninteger\n\n\nNo\n\n\nISCC version number.\n\n\n\n\n\n\n\n\nThe \ngenerate_meta_id\n function must return a valid base32 encoded Meta-ID component without padding.\n\n\nGenerate Meta-ID\n\u00b6\n\n\nAn ISCC generating application must follow these steps in the given order to produce a stable Meta-ID:\n\n\n\n\nApply Unicode standard \nNormalization Form KC (NFKC)\n separately to all text input values.\n\n\nRemove all pairs of brackets  \n[]\n,  \n()\n,  \n{}\n, and text inbetween them from \ntitle\n and \ncreators\n fields.\n\n\nTrim all text fields, such that their UTF-8 encoded byte representation does not exceed 128-bytes each. The trim point must be such, that it does not cut into multibyte characters. The results of this operation will later be stored as base metadata on the blockchain.\n\n\nCut all text after the first occurence of a semicolon (\n;\n) if that semicolon is after the first 25 characters of text.\n\n\nTrim each normalized input value to its first 128 characters.\n\n\nApply \nnormalize_text\n to the trimmed \ntitle\n input value.\n\n\nApply \nnormalize_creators\n to the trimmed \ncreators\n input value.\n\n\nApply \nnormalize_text\n to the trimmed \nextra\n input value.\n\n\nConcatenate the results of step 3, 4 and 5 in ascending order.\n\n\nCreate a list of 4 \ncharacter\n \nn-grams\n by sliding \ncharacter\n-wise through the result of step 6.\n\n\nEncode each n-gram from step 7 to an UTF-8 bytestring and calculate its sha256 digest.\n\n\nApply \nsimhash\n to the list sha256 digests from step 8.\n\n\nTrim the resulting byte sequence to the first 7 bytes.\n\n\nPrepend the 1-byte component header according to component type and ISCC version (e.g. \n0x00\n).\n\n\nEncode the resulting 8 byte sequence with base32 (no-padding) and return the result.\n\n\n\n\nDealing with collisions\n\u00b6\n\n\nIdeally we want multiple ISCCs that identify different manifestations of the \nsame intangible creation\n to be automatically grouped by an identical leading Meta-ID component. We call such a natural grouping an \nintended collision\n. Metadata, captured and edited by humans, is notoriously unreliable. By using normalization and a similarity hash on the metadata we account for some of this variation while keeping the Meta-ID component stable. \n\n\nAuto-generated Meta-IDs components are \nexpected\n to miss some intended collisions. An application should check for such \nmissed intended collisions\n before registering a new Meta-ID with the \ncanonical registry\n of ISCCs by conducting a similarity search and asking for user feedback.\n\n\nBut what about \nunintended collisions\n? Such collisions might happen because two \ndifferent intangible creations\n have very similar or even identical metadata. But they might also happen simply by chance. With 2^56 possibile Meta-ID components the probability of random collisions rises in an S-cuved shape with the number of deployed ISCCs (see: \nHash Collision Probabilities\n).  We should keep in mind that, the Meta-ID component is only one part of an ISCC. Sporadic unintended collisions of the Meta-ID component are generally deemed as \nacceptable and expected\n. \n\n\nIf for any reason an application wants to avoid unintended collisions with pre-existing Meta-ID components it may utilze the \nextra\n-field. An application must first generate a Meta-ID without asking the user for input to the \nextra\n-field and then first check for collisions with the \ncanonical registry\n of ISCCs. After it finds a collision with a pre-existing Meta-ID it may display the metadata of the colliding entry and interact with the user to determine if it indeed is an unintended collision. Only if the user indicates an unintended collision, may the application ask for a disambiguation that is than added as an ammendment to the metadata via the \nextra\n-field to create a different Meta-ID component. The application may repeat the pre-existence check until it finds no collision or a user intended collision. The application must not supply autogenerated input to the \nextra\n-field.\n\n\nIt is our opinion that the concept of \nintended collisions\n of Meta-ID components is generally usefull concept and a net positive. But one must be aware that this characteristic also has its pitfalls. It is by no means an attempt to provide an unambigous - agreed upon - definition of \n\"identical intangible creations\"\n.\n\n\nContent-ID\n\u00b6\n\n\nThe Content-ID component has multiple subtypes. Except for the \nmixed type\n all subtypes correspond with the \nGeneric Media Types\n. A fully qualified ISCC can only have a Content-ID component of one specific type, but there can be multiple ISCCs with different Content-ID types per digital media object.\n\n\nA Content-ID is generated in two broad steps. In the first step, we extract and convert content from a rich media type to a normalized \nGMT\n. In the second step, we use a \nGMT\n-specific process to generate the Content-ID component of an ISCC. \n\n\nContent-ID Types\n\u00b6\n\n\nThe  Content-ID type is signaled by the first 3 bits of the second nibble of the first byte of the Content-ID:\n\n\n\n\n\n\n\n\nConent-ID Type\n\n\nNibble-2 Bits 0-3\n\n\n\n\n\n\n\n\n\n\ntext\n\n\n000\n\n\n\n\n\n\nimage\n\n\n001\n\n\n\n\n\n\naudio\n\n\n010\n\n\n\n\n\n\nvideo\n\n\n011\n\n\n\n\n\n\nmixed\n\n\n100\n\n\n\n\n\n\nReserved\n\n\n101, 110, 111\n\n\n\n\n\n\n\n\nPartial Content Flag (\nPCF\n)\n\u00b6\n\n\nThe last bit of the header byte is the \"Partial Content Flag\". It designates if the Content-ID applies to the full content or just some part of it. The \nPCF\n must be set as a \n0\n-bit (full \nGMT\n-specific content) by default. Setting the \nPCF\n to \n1\n enables applications to create multiple ISCCs for partial extracts of one and the same digital file. The exact semantics of \npartial content\n are outside of the scope of this specification. Applications that plan to support partial Content-IDs should clearly define their semantics. For example, an application might create separate ISCC for the text contents of multiple articles of a magazine issue. In such a scenario\nthe Meta-, Data-, and Instance-IDs are the compound key for the magazine issue, while the Content-ID-Text component distinguishes the different articles of the issue. The different Content-ID-Text components would automatically be \"bound\" together by the other 3 components.\n\n\nContent-ID-Text\n\u00b6\n\n\nThe Content-ID-Text is built from the extracted plain-text content of an encoded media object. To build a stable Content-ID-Text the plain text content must be extracted in a way that is reproducible. To make this possible we specify that the plain-text content must be extracted with \nApache Tika v1.16\n.\n\n\nData-ID\n\u00b6\n\n\nThe Data-ID is built from the raw encoded data of the content to be identified. An ISCC generating application must provide a \ngenerate_data_id\n function that accepts the raw encoded data as input. Generate a Data-ID by this procedure:\n\n\n\n\nApply \nchunk_data\n to the raw encoded content data\n\n\nFor each chunk calculate the sha256 digest\n\n\nApply \nminhash\n with 256 permutations to the resulting list of digests\n\n\nTake the lowest bit from each minhash value and concatenate them to a 256 string\n\n\nTrim the resulting byte sequence to the first 7 bytes.\n\n\nPrepend the 1-byte component header (e.g. 0x20).\n\n\nEncode the resulting 8-byte sequence with base32 (no-padding) and return the result\n\n\n\n\nInstance-ID\n\u00b6\n\n\nThe Instance-ID is built from the raw data of the media object to be identified and serves as basic checksum for the media object. The raw data of the media object is split into data-chunks. Then we build a hash-tree from those chunks and use the truncated top-hash for the Instance-ID:\n\n\n\n\nAn ISCC generating application must provide a \ngenerate_instance_id\n function that accepts the raw data file as input and returns an encoded Instance-ID. Generate an Instance-ID by this procedure:\n\n\n\n\nApply \nchunk_data\n to the raw bytes of the encoded media object.\n\n\nFor each chunk calculate the sha256d\n4\n digest of the concatenation of a \n0x00\n-byte and the chunk bytes. We call the resulting values \nleaf node hashes\n (\nLNH\n).\n\n\nCalculate the next level of the hash tree by applying sha256d to the concatenation of a \n0x01\n-byte and adjacent pairs of \nLNH\n values. If the length of the list of \nLNH\n values is uneven concatenate the last \nLNH\n value with itself. We call the resulting values \ninternal node hashes\n (\nINH\n).\n\n\nRecursively apply \n0x01\n-prefixed pairwise hashing to the results of  step 3 until the process yields only one hash value. We call this value the \ntop hash\n5\n.\n\n\nTrim the resulting \ntop hash\n to the first 7 bytes.\n\n\nPrepend the 1-byte component header (e.g. \n0x30\n).\n\n\nEncode the resulting 8-byte sequence with base32 (no-padding) and return the result.\n\n\n\n\nApplications may carry, store, and process the full hash-tree for advanced partial data integrity verification.\n\n\nProcedures & Algorithms\n\u00b6\n\n\nNormalize Text\n\u00b6\n\n\nWe define a text normalization function that is specific to our application. It takes unicode text as an input and returns \nnormalized\n Unicode text for further algorithmic processing. We reference this function by the name \nnormalize_text\n. The \nnormalize_text\n function performs the following operations in the given order while each step works with the results of the previous operation:\n\n\n\n\nDecompose the input text by applying \nUnicode Normalization Form D (NFD)\n.\n\n\nReplace each group of one or more consecutive \nSeparator\n characters (\nUnicode categories\n Zs, Zl and Zp) with exactly one Unicode \nSPACE\n \ncharacter\n (\nU+0020\n) .\n\n\nRemove any leading or trailing \nSeparator\n characters.\n\n\nRemove each \ncharacter\n that is not in one of the Unicode categories \nSeparator\n , \nLetter\n, \nNumber\n or \nSymbol\n.\n\n\nConvert all characters to their lower case\n\n\nRe-Compose the text by applying \nUnicode Normalization Form C (NFC)\n.\n\n\nReturn the resulting text\n\n\n\n\nNormalize Creators\n\u00b6\n\n\n\n\nTodo\n\n\nSpecify \nnormalize_creator\n function\n\n\n\n\nTokenize Text\n\u00b6\n\n\n\n\nTodo\n\n\nSpecify \ntokenize_text\n function\n\n\n\n\nFootnotes\n\u00b6\n\n\n\n\n\n\n\n\n\n\nBase Encoding:\n The final base encoding of this specification might change before version 1. Base32 was chosen because it is a widely accepted standard and has implementations in most popular programming languages. It is url safe, case insensitive and encodes the ISCC octets to a fixed size alphanumeric string. The predictable size of the encoding is a property that we need for composition and decomposition of components without having to rely on a delimiter (hyphen) in the ISCC code representation. We might change to a non standard base62, mixed case encoding to create shorter ISCC codes before the final version 1 specification.\u00a0\n\u21a9\n\n\n\n\n\n\nComponents structure:\n We might switch to a different base structure for components. For example we might use a variable length header and a bigger 8-byte body. The header would only be carried in the encoded representation and applications could use full 64-bit space per component. As similarity searches accross different components make no sense, the type information contained in the header of each component can be safely ignored after an ISCC has been decomposed and internaly typed by an application.\u00a0\n\u21a9\n\n\n\n\n\n\nMeta-ID creators field:\n We have tested multiple normalization strategies for \ncreators\n metadata and it works fairly well. The optional \ncreators\n-field is a strong discriminator when dealing with similar title texts. But our tests indicate that the main problem for a generic conent identifier is in the semantic ambiguity of the \ncreators\n-field accross industries. For example, who would you list as the creators of a movie, the directors, writers, main actors? Would you list some of them or if not how do you decide whom you will list. We will do some more evaluation and might remove the \ncreators\n-field altogether for the final version 1 specification. All disambiguation of similar title data would then have to move to the \nextra\n-field.\u00a0\n\u21a9\n\n\n\n\n\n\nInstance-ID data integrity:\n  To guard against length-extension attacks and second pre-image attacks we use double sha256 for hashing. We also prefix the hash input data with a \n0x00\n-byte for the leaf nodes hashes and with a \n0x01\n-byte for the  internal node hashes.\u00a0\n\u21a9\n\n\n\n\n\n\nInstance-ID binding:\n We might add an additional step to the final Instance-ID component by hashing the concatenation of the preceeding components and the \ntop-hash\n. This would bind the Instance-ID to the other components. But this would also chainge its semantics to encode integrity of data and metadata together.\u00a0\n\u21a9",
            "title": "Specification (Draft)"
        },
        {
            "location": "/specification/#iscc-specification-draft",
            "text": "Warning  This document is a work in progress draft! It may be updated, replaced, or obsoleted by other documents at any time. This document must not be used as reference material or cited other than as \"work in progress\".",
            "title": "ISCC - Specification Draft"
        },
        {
            "location": "/specification/#abstract",
            "text": "The  International Standard Content Code  (ISCC), is an open and decentralized digital media identifier. An ISCC can be created from digital content and its basic metadata by anybody who follows the procedures of the ISCC specification or by using open source software that supports ISCC creation conforming to the ISCC specification.",
            "title": "Abstract"
        },
        {
            "location": "/specification/#note-to-readers",
            "text": "For public discussion of issues for this draft please use the Github issue tracker:  https://github.com/coblo/iscc-specs/issues .  The latest published version of this draft can be found at  http://iscc.codes/specification/ .   Public discussion and contributions are welcome.",
            "title": "Note to Readers"
        },
        {
            "location": "/specification/#about-this-document",
            "text": "This document proposes an open and vendor neutral ISCC standard and describes the technical procedures to create and manage ISCC identifiers. It is produced by the  Content Blockchain Project  and it aimed to become the definitive guide to the ISCC standard for technical implementors. The content is determined by its authors in an open consensus process.",
            "title": "About this Document"
        },
        {
            "location": "/specification/#conventions-and-terminology",
            "text": "The key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\", \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"MAY\", and \"OPTIONAL\" in this document are to be interpreted as described in  RFC 2119  [RFC2119].",
            "title": "Conventions and Terminology"
        },
        {
            "location": "/specification/#definitions",
            "text": "GMT  Generic Media Type: A basic digital content type such as UTF-8 encoded plain text or raw pixel data.  ISCC  International Standard Content Code  ISCC Code  The base32 encoded representation of an ISCC  ISCC Digest  The raw binary data of an ISCC  ISCC ID  The integer representation of an ISCC",
            "title": "Definitions"
        },
        {
            "location": "/specification/#introduction",
            "text": "The ISCC aims to permanently identify the content of a given digital media object at multiple levels of  granularity . It is algorithmically generated from basic metadata and the contents of the digital media object which it identifies. It is designed for being registered and stored on a public decentralized blockchain. An ISCC for a media object can be created by anybody, not just by the author or publisher of a content or by a centralized registrar. By itself the ISCC does not make any statement or claim about authorship or ownership of the identified content.",
            "title": "Introduction"
        },
        {
            "location": "/specification/#iscc-structure",
            "text": "The  ISCC Digest  is a fixed size sequence of 32 bytes (256 bits) assembled from multiple sub-components. The printable  ISCC Code  is an  RFC 4648  base32 1  encoded string representation of an  ISCC Digest . This is a high-level overview of the ISCC creation process:",
            "title": "ISCC Structure"
        },
        {
            "location": "/specification/#components",
            "text": "The  ISCC Digest  is built from multiple self-describing 64-bit components:     Components:  Meta-ID  Content-ID  Data-ID  Instance-ID      Context:  Intangible creation  Content similarity  Data similarity  Data checksum    Input:  Metadata  Extracted  content  Raw data  Raw data    Algorithms:  Similarity Hash  Type specific  CDC , Similarity Hash  CDC , Hash Tree    Size:  64 bits  64 bits  64 bits  64 bits     Each component is guaranteed to fit into a 64-bit unsigned integer value. The components may be used independently by applications for various purposes but must be combined into a 52  character  string (55 with hyphens) for a fully qualified ISCC code. The components must be combined in the fixed order of Meta-ID, Content-ID, Data-ID, Instance-ID and may be separated by hyphens.   Todo  Describe coded format with prefix, colon, components +- hyphens",
            "title": "Components"
        },
        {
            "location": "/specification/#component-types",
            "text": "Each component has the same basic structure of a 1-byte header and a 7-byte main section 2 . Each component can thus be fit into a 64-bit integer value. The header-byte of each component is subdivided into 2 nibbles (4 bits). The first nibble specifies the component type while the second nibble is component specific.     Component  Nibble-1  Nibble-2  Byte      Meta-ID  0000  0000 - ISCC version (0)  0x00    Content-ID  0001  0000 - ContentType Text (0)  0x10    Data-ID  0010  0000 - Reserved  0x20    Instance-ID  0011  0000 - Reserved  0x30",
            "title": "Component types"
        },
        {
            "location": "/specification/#meta-id",
            "text": "The Meta-ID is built from minimal and generic metadata of the content to be identified. All  text  information supplied to the META-ID generating function is assumed to be UTF-8 encoded. Errors during decoding the bytestring input to a native Unicode must terminate the process and should not be silenced. An ISCC generating application must provide a  generate_meta_id  function that accepts the following input fields:     Name  Type  Required  Description      title  text  Yes  The title of an intangible creation.    creators 3  text  No  One or more semicolon separated names of the original creators of the content.    extra  text  No  A short statement that distinguishes this intangible creation from another one.    version  integer  No  ISCC version number.     The  generate_meta_id  function must return a valid base32 encoded Meta-ID component without padding.",
            "title": "Meta-ID"
        },
        {
            "location": "/specification/#generate-meta-id",
            "text": "An ISCC generating application must follow these steps in the given order to produce a stable Meta-ID:   Apply Unicode standard  Normalization Form KC (NFKC)  separately to all text input values.  Remove all pairs of brackets   [] ,   () ,   {} , and text inbetween them from  title  and  creators  fields.  Trim all text fields, such that their UTF-8 encoded byte representation does not exceed 128-bytes each. The trim point must be such, that it does not cut into multibyte characters. The results of this operation will later be stored as base metadata on the blockchain.  Cut all text after the first occurence of a semicolon ( ; ) if that semicolon is after the first 25 characters of text.  Trim each normalized input value to its first 128 characters.  Apply  normalize_text  to the trimmed  title  input value.  Apply  normalize_creators  to the trimmed  creators  input value.  Apply  normalize_text  to the trimmed  extra  input value.  Concatenate the results of step 3, 4 and 5 in ascending order.  Create a list of 4  character   n-grams  by sliding  character -wise through the result of step 6.  Encode each n-gram from step 7 to an UTF-8 bytestring and calculate its sha256 digest.  Apply  simhash  to the list sha256 digests from step 8.  Trim the resulting byte sequence to the first 7 bytes.  Prepend the 1-byte component header according to component type and ISCC version (e.g.  0x00 ).  Encode the resulting 8 byte sequence with base32 (no-padding) and return the result.",
            "title": "Generate Meta-ID"
        },
        {
            "location": "/specification/#dealing-with-collisions",
            "text": "Ideally we want multiple ISCCs that identify different manifestations of the  same intangible creation  to be automatically grouped by an identical leading Meta-ID component. We call such a natural grouping an  intended collision . Metadata, captured and edited by humans, is notoriously unreliable. By using normalization and a similarity hash on the metadata we account for some of this variation while keeping the Meta-ID component stable.   Auto-generated Meta-IDs components are  expected  to miss some intended collisions. An application should check for such  missed intended collisions  before registering a new Meta-ID with the  canonical registry  of ISCCs by conducting a similarity search and asking for user feedback.  But what about  unintended collisions ? Such collisions might happen because two  different intangible creations  have very similar or even identical metadata. But they might also happen simply by chance. With 2^56 possibile Meta-ID components the probability of random collisions rises in an S-cuved shape with the number of deployed ISCCs (see:  Hash Collision Probabilities ).  We should keep in mind that, the Meta-ID component is only one part of an ISCC. Sporadic unintended collisions of the Meta-ID component are generally deemed as  acceptable and expected .   If for any reason an application wants to avoid unintended collisions with pre-existing Meta-ID components it may utilze the  extra -field. An application must first generate a Meta-ID without asking the user for input to the  extra -field and then first check for collisions with the  canonical registry  of ISCCs. After it finds a collision with a pre-existing Meta-ID it may display the metadata of the colliding entry and interact with the user to determine if it indeed is an unintended collision. Only if the user indicates an unintended collision, may the application ask for a disambiguation that is than added as an ammendment to the metadata via the  extra -field to create a different Meta-ID component. The application may repeat the pre-existence check until it finds no collision or a user intended collision. The application must not supply autogenerated input to the  extra -field.  It is our opinion that the concept of  intended collisions  of Meta-ID components is generally usefull concept and a net positive. But one must be aware that this characteristic also has its pitfalls. It is by no means an attempt to provide an unambigous - agreed upon - definition of  \"identical intangible creations\" .",
            "title": "Dealing with collisions"
        },
        {
            "location": "/specification/#content-id",
            "text": "The Content-ID component has multiple subtypes. Except for the  mixed type  all subtypes correspond with the  Generic Media Types . A fully qualified ISCC can only have a Content-ID component of one specific type, but there can be multiple ISCCs with different Content-ID types per digital media object.  A Content-ID is generated in two broad steps. In the first step, we extract and convert content from a rich media type to a normalized  GMT . In the second step, we use a  GMT -specific process to generate the Content-ID component of an ISCC.",
            "title": "Content-ID"
        },
        {
            "location": "/specification/#content-id-types",
            "text": "The  Content-ID type is signaled by the first 3 bits of the second nibble of the first byte of the Content-ID:     Conent-ID Type  Nibble-2 Bits 0-3      text  000    image  001    audio  010    video  011    mixed  100    Reserved  101, 110, 111",
            "title": "Content-ID Types"
        },
        {
            "location": "/specification/#partial-content-flag-pcf",
            "text": "The last bit of the header byte is the \"Partial Content Flag\". It designates if the Content-ID applies to the full content or just some part of it. The  PCF  must be set as a  0 -bit (full  GMT -specific content) by default. Setting the  PCF  to  1  enables applications to create multiple ISCCs for partial extracts of one and the same digital file. The exact semantics of  partial content  are outside of the scope of this specification. Applications that plan to support partial Content-IDs should clearly define their semantics. For example, an application might create separate ISCC for the text contents of multiple articles of a magazine issue. In such a scenario\nthe Meta-, Data-, and Instance-IDs are the compound key for the magazine issue, while the Content-ID-Text component distinguishes the different articles of the issue. The different Content-ID-Text components would automatically be \"bound\" together by the other 3 components.",
            "title": "Partial Content Flag (PCF)"
        },
        {
            "location": "/specification/#content-id-text",
            "text": "The Content-ID-Text is built from the extracted plain-text content of an encoded media object. To build a stable Content-ID-Text the plain text content must be extracted in a way that is reproducible. To make this possible we specify that the plain-text content must be extracted with  Apache Tika v1.16 .",
            "title": "Content-ID-Text"
        },
        {
            "location": "/specification/#data-id",
            "text": "The Data-ID is built from the raw encoded data of the content to be identified. An ISCC generating application must provide a  generate_data_id  function that accepts the raw encoded data as input. Generate a Data-ID by this procedure:   Apply  chunk_data  to the raw encoded content data  For each chunk calculate the sha256 digest  Apply  minhash  with 256 permutations to the resulting list of digests  Take the lowest bit from each minhash value and concatenate them to a 256 string  Trim the resulting byte sequence to the first 7 bytes.  Prepend the 1-byte component header (e.g. 0x20).  Encode the resulting 8-byte sequence with base32 (no-padding) and return the result",
            "title": "Data-ID"
        },
        {
            "location": "/specification/#instance-id",
            "text": "The Instance-ID is built from the raw data of the media object to be identified and serves as basic checksum for the media object. The raw data of the media object is split into data-chunks. Then we build a hash-tree from those chunks and use the truncated top-hash for the Instance-ID:   An ISCC generating application must provide a  generate_instance_id  function that accepts the raw data file as input and returns an encoded Instance-ID. Generate an Instance-ID by this procedure:   Apply  chunk_data  to the raw bytes of the encoded media object.  For each chunk calculate the sha256d 4  digest of the concatenation of a  0x00 -byte and the chunk bytes. We call the resulting values  leaf node hashes  ( LNH ).  Calculate the next level of the hash tree by applying sha256d to the concatenation of a  0x01 -byte and adjacent pairs of  LNH  values. If the length of the list of  LNH  values is uneven concatenate the last  LNH  value with itself. We call the resulting values  internal node hashes  ( INH ).  Recursively apply  0x01 -prefixed pairwise hashing to the results of  step 3 until the process yields only one hash value. We call this value the  top hash 5 .  Trim the resulting  top hash  to the first 7 bytes.  Prepend the 1-byte component header (e.g.  0x30 ).  Encode the resulting 8-byte sequence with base32 (no-padding) and return the result.   Applications may carry, store, and process the full hash-tree for advanced partial data integrity verification.",
            "title": "Instance-ID"
        },
        {
            "location": "/specification/#procedures-algorithms",
            "text": "",
            "title": "Procedures &amp; Algorithms"
        },
        {
            "location": "/specification/#normalize-text",
            "text": "We define a text normalization function that is specific to our application. It takes unicode text as an input and returns  normalized  Unicode text for further algorithmic processing. We reference this function by the name  normalize_text . The  normalize_text  function performs the following operations in the given order while each step works with the results of the previous operation:   Decompose the input text by applying  Unicode Normalization Form D (NFD) .  Replace each group of one or more consecutive  Separator  characters ( Unicode categories  Zs, Zl and Zp) with exactly one Unicode  SPACE   character  ( U+0020 ) .  Remove any leading or trailing  Separator  characters.  Remove each  character  that is not in one of the Unicode categories  Separator  ,  Letter ,  Number  or  Symbol .  Convert all characters to their lower case  Re-Compose the text by applying  Unicode Normalization Form C (NFC) .  Return the resulting text",
            "title": "Normalize Text"
        },
        {
            "location": "/specification/#normalize-creators",
            "text": "Todo  Specify  normalize_creator  function",
            "title": "Normalize Creators"
        },
        {
            "location": "/specification/#tokenize-text",
            "text": "Todo  Specify  tokenize_text  function",
            "title": "Tokenize Text"
        },
        {
            "location": "/specification/#footnotes",
            "text": "Base Encoding:  The final base encoding of this specification might change before version 1. Base32 was chosen because it is a widely accepted standard and has implementations in most popular programming languages. It is url safe, case insensitive and encodes the ISCC octets to a fixed size alphanumeric string. The predictable size of the encoding is a property that we need for composition and decomposition of components without having to rely on a delimiter (hyphen) in the ISCC code representation. We might change to a non standard base62, mixed case encoding to create shorter ISCC codes before the final version 1 specification.\u00a0 \u21a9    Components structure:  We might switch to a different base structure for components. For example we might use a variable length header and a bigger 8-byte body. The header would only be carried in the encoded representation and applications could use full 64-bit space per component. As similarity searches accross different components make no sense, the type information contained in the header of each component can be safely ignored after an ISCC has been decomposed and internaly typed by an application.\u00a0 \u21a9    Meta-ID creators field:  We have tested multiple normalization strategies for  creators  metadata and it works fairly well. The optional  creators -field is a strong discriminator when dealing with similar title texts. But our tests indicate that the main problem for a generic conent identifier is in the semantic ambiguity of the  creators -field accross industries. For example, who would you list as the creators of a movie, the directors, writers, main actors? Would you list some of them or if not how do you decide whom you will list. We will do some more evaluation and might remove the  creators -field altogether for the final version 1 specification. All disambiguation of similar title data would then have to move to the  extra -field.\u00a0 \u21a9    Instance-ID data integrity:   To guard against length-extension attacks and second pre-image attacks we use double sha256 for hashing. We also prefix the hash input data with a  0x00 -byte for the leaf nodes hashes and with a  0x01 -byte for the  internal node hashes.\u00a0 \u21a9    Instance-ID binding:  We might add an additional step to the final Instance-ID component by hashing the concatenation of the preceeding components and the  top-hash . This would bind the Instance-ID to the other components. But this would also chainge its semantics to encode integrity of data and metadata together.\u00a0 \u21a9",
            "title": "Footnotes"
        },
        {
            "location": "/contributing/",
            "text": "",
            "title": "Contributing"
        },
        {
            "location": "/license/",
            "text": "License\n\u00b6\n\n\nCC BY-NC-SA 4.0 License\n\n\nCopyright \u00a9 2016 - 2017 Content Blockchain Project\n\n\nThis work is licensed under a \nCreative Commons Attribution-ShareAlike 4.0 International License\n.",
            "title": "License"
        },
        {
            "location": "/license/#license",
            "text": "CC BY-NC-SA 4.0 License  Copyright \u00a9 2016 - 2017 Content Blockchain Project  This work is licensed under a  Creative Commons Attribution-ShareAlike 4.0 International License .",
            "title": "License"
        }
    ]
}